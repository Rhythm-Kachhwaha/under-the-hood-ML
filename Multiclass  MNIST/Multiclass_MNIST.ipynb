{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7da87f4",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Goal of Softmax Regression on MNIST**\n",
    "\n",
    "* **Problem Type:** Multi-class classification (10 classes: digits 0â€“9).\n",
    "* **Objective:** Learn a **linear mapping + softmax** that predicts which digit an image belongs to.\n",
    "\n",
    "  * Itâ€™s the **baseline model** for multi-class classification.\n",
    "  * It tests if our data pipeline + math (softmax + cross-entropy) are implemented correctly.\n",
    "  * Gives a benchmark (\\~92% accuracy) before moving to deeper models like MLPs or CNNs.\n",
    "\n",
    "Think of it as:\n",
    "ðŸ‘‰ \"Given a handwritten digit image, can my model correctly classify it into one of the 10 categories using just a linear transformation + softmax?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1def725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sklearn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c6c63",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e7b8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f68b9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784)\n",
      "y shape: (70000,)\n",
      "X size: 54880000\n",
      "y size: 70000\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\") \n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X size: {X.size}\")\n",
    "print(f\"y size: {y.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93dd887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3ad9676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train : 56000\n",
      "y train : 56000\n",
      "y test : 14000\n",
      "y test : 14000\n"
     ]
    }
   ],
   "source": [
    "print(f\"X train : {len(X_train)}\")\n",
    "print(f\"y train : {len(y_train)}\")\n",
    "print(f\"y test : {len(X_test)}\")\n",
    "print(f\"y test : {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b46354",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fda7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.values.reshape(-1,28,28)\n",
    "y_train_labels = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57abbfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_images(images, labels, num_images = 10):\n",
    "    \"\"\"Args:\n",
    "        images (np.ndarray): The dataset of images (e.g., X_train_reshaped).\n",
    "        labels (np.ndarray): The corresponding labels (e.g., y_train_labels).\n",
    "        num_images (int): The number of images to display.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, num_images, figsize = (15,3))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "\n",
    "        # Set the title to the corresponding label\n",
    "        ax.set_title(f'Label: {labels[i]}')\n",
    "\n",
    "        # Turn off the axes for a cleaner look\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_images(X_train_reshaped, y_train_labels, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dfaf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db4c22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCLASSIFICATION:\n",
    "    \"\"\"\n",
    "    A simple two layer neural network for MNIST classifiation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_size,hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases of the neural network.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of features in the input data (e.g., 784 for MNIST).\n",
    "            hidden_size (int): The number of neurons in the hidden layer.\n",
    "            output_size (int): The number of classes (e.g., 10 for digits 0-9).\n",
    "        \"\"\"\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1,hidden_size))\n",
    "\n",
    "        self.W2 = np.random.randn(hidden_size,output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def relu(self,z):\n",
    "        ### ReLU activation function\n",
    "        return np.max(0,z)\n",
    "    def relu_derivative(self, z):\n",
    "        \"\"\"\n",
    "        Computes the derivative of the ReLU function.\n",
    "        \"\"\"\n",
    "        return (z > 0).astype(float)\n",
    "    \n",
    "    def softmax(self,z):\n",
    "        exp_z = np.exp(z- np.max(z, axis = 1,keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        # layer 1\n",
    "        Z1 = np.dot(X,self.W1) + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "\n",
    "        #layer 2\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.softmax(Z2)\n",
    "\n",
    "        return Z1, A1, Z2\n",
    "    \n",
    "    def compute_loss(self, y, y_hat):\n",
    "        \"\"\"\n",
    "        Computes the cross-entropy loss.\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "        # Cross-entropy loss formula\n",
    "        loss = -np.sum(y * np.log(y_hat + 1e-8)) / m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y, Z1, A1, A2):\n",
    "        \"\"\"\n",
    "        Performs the backward pass to compute gradients.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): The input data.\n",
    "            y (np.ndarray): The true labels (one-hot encoded).\n",
    "            Z1, A1, A2: Outputs from the forward pass.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Gradients of the loss with respect to W1, b1, W2, and b2.\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "\n",
    "        #o/p gradients\n",
    "    # Output layer gradients\n",
    "        dZ2 = A2 - y  # Simple and elegant derivative for Softmax with Cross-Entropy\n",
    "        dW2 = np.dot(A1.T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Hidden layer gradients\n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * self.relu_derivative(Z1)\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        return dW1, db1, dW2, db2\n",
    "\n",
    "    def update_parameters(self, dW1, db1, dW2, db2, learning_rate):\n",
    "        \"\"\"\n",
    "        Updates the weights and biases using gradient descent.\n",
    "        \"\"\"\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "    \n",
    "    def train(self,X_train,y_train,epochs,learning_rate):\n",
    "        # One-hot encode the labels\n",
    "        num_classes = self.W2.shape[1]\n",
    "        y_train_one_hot = np.eye(num_classes)[y_train.astype(int)]\n",
    "        for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "            # Forward pass\n",
    "            Z1, A1, A2 = self.forward(X_train)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(y_train_one_hot, A2)\n",
    "            \n",
    "            # Backward pass (compute gradients)\n",
    "            dW1, db1, dW2, db2 = self.backward(X_train, y_train_one_hot, Z1, A1, A2)\n",
    "\n",
    "            # Update parameters\n",
    "            self.update_parameters(dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "            # Print loss every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85efb175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run the training loop\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining finished!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 97\u001b[0m, in \u001b[0;36mMNISTCLASSIFICATION.train\u001b[1;34m(self, X_train, y_train, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     94\u001b[0m y_train_one_hot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(num_classes)[y_train\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Progress\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     Z1, A1, A2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(y_train_one_hot, A2)\n",
      "Cell \u001b[1;32mIn[32], line 37\u001b[0m, in \u001b[0;36mMNISTCLASSIFICATION.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# layer 1\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     Z1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW1) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1\n\u001b[1;32m---> 37\u001b[0m     A1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m#layer 2\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     Z2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2\n",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m, in \u001b[0;36mMNISTCLASSIFICATION.relu\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(\u001b[38;5;28mself\u001b[39m,z):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m### ReLU activation function\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rhythm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2698\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rhythm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Let's define the model parameters\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Instantiate the model\n",
    "model = MNISTCLASSIFICATION(input_size, hidden_size, output_size)\n",
    "\n",
    "# Run the training loop\n",
    "print(\"Starting training...\")\n",
    "model.train(X_train.values, y_train.values, epochs, learning_rate)\n",
    "print(\"Training finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
