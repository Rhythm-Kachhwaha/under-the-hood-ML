{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080d9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840ed2b",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6a8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### known params (weights and biases)\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "### data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start,end,step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e1e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : torch.Size([50, 1])\n",
      "X size : torch.Size([50, 1])\n",
      "Number of samples : 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape : {X.shape}\")\n",
    "print(f\"X size : {X.size()}\")\n",
    "print(f\"Number of samples : {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849e2de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 samples of X and Y\n",
      "X : tensor([[0.0000],\n",
      "        [0.0200],\n",
      "        [0.0400],\n",
      "        [0.0600],\n",
      "        [0.0800],\n",
      "        [0.1000],\n",
      "        [0.1200],\n",
      "        [0.1400],\n",
      "        [0.1600],\n",
      "        [0.1800]])\n",
      "y : tensor([[0.3000],\n",
      "        [0.3140],\n",
      "        [0.3280],\n",
      "        [0.3420],\n",
      "        [0.3560],\n",
      "        [0.3700],\n",
      "        [0.3840],\n",
      "        [0.3980],\n",
      "        [0.4120],\n",
      "        [0.4260]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 10 samples of X and Y\")\n",
    "print(\"X :\", X[:10])\n",
    "print(\"y :\", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "545933a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "### train and test split 80 and 20 %\n",
    "train_split = int(0.8*(len(X)))\n",
    "\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83aa6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data, train_labels, test_data, test_labels, predictions = None):\n",
    "    plt.figure(figsize=(10,7))\n",
    "\n",
    "    #train data\n",
    "    plt.scatter(train_data,train_labels,c = \"b\",s = 4,label = \"training data\")\n",
    "    \n",
    "    #test data\n",
    "    plt.scatter(test_data,test_labels,c = \"g\",s = 4,label = \"test data\")\n",
    "\n",
    "    #predictions if there are:\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c=\"r\",s=4,label = \"Predictions\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ba0aed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(X_train, y_train, X_test, y_test, predictions=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466845e5",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61877685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                                requires_grad=True,\n",
    "                                                dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float))\n",
    "    \n",
    "\n",
    "    def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights*x + self.bias  ### linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b697979",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "630d7a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1.0473], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.5868], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionModel()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b24a44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([1.0473])), ('bias', tensor([-1.5868]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e608c",
   "metadata": {},
   "source": [
    "### Training the loop (the best part)\n",
    "* we need to define a loss function\n",
    "* an optimizer\n",
    "* setup a lr(learning rate)\n",
    "* the whole idea for a model to move from some unkonw para to somes known para OR in another words poor to better representation of the data\n",
    "* one way to measure how poor or how wrong predictions are to use a loss function\n",
    "* Loss/Cost functions quantify the performance of machine-learning (ML) models by comparing their predictions to ground truth values.\n",
    "* things we need to train:\n",
    "* a loss fn measures how wrong models predictions are compared to ideal outputs.\n",
    "* optimizer takes into account the loss of a model and adjusts the models parameters (weigths and biases) to improve the loss fn and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08aa0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup loss fn\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "### setup optimizer\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), \n",
    "                            lr = 0.01)#learning rate = most important learning hyperparameter that we set it will change values as 0.0x for 0.1 -> 0.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13c6720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 0.7\n",
      "Bias : 0.3\n"
     ]
    }
   ],
   "source": [
    "### now our goal is to train the trainable params which are weights and bias (for our model)\n",
    "### we need to train our model to get as close to these biases\n",
    "print(f\"Weight : {weight}\")\n",
    "print(f\"Bias : {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b748ef",
   "metadata": {},
   "source": [
    "### Train loop\n",
    "need to run many times to actually fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c69a6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.0036550797522068024\n",
      "Epoch : 0 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 10 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 20 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 30 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 40 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 50 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 60 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 70 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 80 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 90 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 100 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 110 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 120 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 130 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 140 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 150 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 160 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 170 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 180 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 190 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 200 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 210 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 220 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 230 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 240 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 250 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 260 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 270 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 280 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 290 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 300 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 310 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 320 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 330 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 340 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 350 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 360 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 370 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 380 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 390 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 400 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 410 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 420 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 430 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 440 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 450 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 460 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 470 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 480 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "Epoch : 490 | Loss:  0.0036550797522068024 | Test Loss: 0.012627387419342995\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n",
      "loss :  0.0036550797522068024\n",
      "OrderedDict([('weights', tensor([0.7095])), ('bias', tensor([0.3042]))])\n",
      "loss :  0.007865902036428452\n",
      "OrderedDict([('weights', tensor([0.7056])), ('bias', tensor([0.2942]))])\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train() # -> set model to train mode\n",
    "\n",
    "    #1. forward pass\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    #2. calculate loss\n",
    "    loss = loss_fn(y_pred,y_train) # model_pred,target\n",
    "    print(f\"loss :  {loss}\")\n",
    "\n",
    "    #3. Optimizer zero grad : #how the opti will accumulate through the loop we have to zero them in this step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #4. backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    #5. optimizer.step (perform gradient descent)\n",
    "    optimizer.step()\n",
    "\n",
    "    ### now test set to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode(): # turn off grad tracking\n",
    "        test_pred = model(X_test) # forward pass\n",
    "\n",
    "        #calculate loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "        if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            loss_values.append(loss_values)\n",
    "            test_loss_values.append(test_loss_values)\n",
    "            print(f\"Epoch : {epoch} | Loss:  {loss} | Test Loss: {test_loss}\")\n",
    "\n",
    "        #print state dict\n",
    "        print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5977fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred_new = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9100bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(X_train, y_train, X_test, y_test,predictions=y_pred_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
